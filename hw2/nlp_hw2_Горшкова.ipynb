{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw2_Горшкова.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlBrhpi-ZXlz",
        "outputId": "9bcef335-f2b3-4d0e-cab3-adafd1cf8c0f"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "! pip install pymystem3==0.1.10\n",
        "from pymystem3 import mystem\n",
        "\n",
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "! pip install spacy==3.0.0\n",
        "import spacy\n",
        "!spacy download ru_core_news_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting pymystem3==0.1.10\n",
            "  Downloading pymystem3-0.1.10-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pymystem3==0.1.10) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.1.10) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.1.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.1.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.1.10) (2021.5.30)\n",
            "Installing collected packages: pymystem3\n",
            "  Attempting uninstall: pymystem3\n",
            "    Found existing installation: pymystem3 0.2.0\n",
            "    Uninstalling pymystem3-0.2.0:\n",
            "      Successfully uninstalled pymystem3-0.2.0\n",
            "Successfully installed pymystem3-0.1.10\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting spacy==3.0.0\n",
            "  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 226 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (4.8.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (0.4.1)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 15.8 MB/s \n",
            "\u001b[?25hCollecting pathy\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (57.4.0)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (21.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (3.7.4.3)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
            "\u001b[K     |████████████████████████████████| 623 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.23.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3.0.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy==3.0.0) (5.2.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.0 pydantic-1.7.4 spacy-3.0.0 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 typer-0.3.2\n",
            "Collecting ru-core-news-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.0.0/ru_core_news_sm-3.0.0-py3-none-any.whl (17.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.9 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymorphy2>=0.9 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.0.0) (0.9.1)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.0.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.0.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.0.0) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (8.0.10)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (4.8.1)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (57.4.0)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy<3.1.0,>=3.0.0->ru-core-news-sm==3.0.0) (5.2.1)\n",
            "Installing collected packages: ru-core-news-sm\n",
            "Successfully installed ru-core-news-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ievl1O1oSin"
      },
      "source": [
        "Корпус = несколько случайных твитов. Почему это хороший корпус для поверки теггеров: \n",
        "1. очень много новых слов, которые скорее всего не содержатся в словаре, если теггер работает на словаре (чё, кринж, бател, тик ток, ресейл, алик...); \n",
        "2. дефисные токены (какой-то, соотеч-ов, андроид-разработчик); \n",
        "3. неопопулярные сокращения (зап., предл., чел.);\n",
        "4. аббревиатуры (МИД, США, ДТП);\n",
        "5. смена языка+раскладки (Essex Fells, New Jersey) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sghyekqd3G-"
      },
      "source": [
        "corpus = [\"\"\"чё с мужиками..... они типа просто сидят и у них в голове таракан такой..... давай зайдём к левой девушке и скинем свой вонючий омерзительный ненужный отросток\n",
        "словила не отвращение а смех и кринж когда какой-то щегол говорит мне такое\"\"\",\n",
        "\"\"\"Ресторатор сообщил, что открывает 3 новых проекта , которые не связаны с бател репом и денег у него осталось на 2 месяца жизни, а Versus ушёл в минус с ноября 2019 года.\n",
        "какие проекты откроет Ресторатор?\n",
        "мои варики:\n",
        "аккаунт в Тик Токе\n",
        "кальянная\n",
        "ресейл чехлов на айфоны с Алика\"\"\",\n",
        "\"\"\"МИД предл. застрявшим в США рос. пожить у соотеч-ов\n",
        "Сколько чел. сможет размест. депутат ГД  Фетисов в своем доме в городке Essex Fells, штат New Jersey? \n",
        "Кто застрял на зап. побережье -предл. дом семьи Абызовых в Малибу, штата Калифорния, куплен за шесть с половиной миллионов долларов.Это все наши налоги\"\"\",\n",
        "\"\"\"Минобр Китая призвал усилить контроль за трехколесными транспортными средствами после гибели четырех несовершеннолетних в ДТП под Харбином. Они угодили под фуру, за рулем находится их сверстник без водительского удостоверения\"\"\",\n",
        "\"\"\"Управляющего директора Сбербанка Зака арестовали по подозрению в мошенничестве.\n",
        "Прям Сбер пошли ворошить\"\"\", \n",
        "\"\"\"Жду пока андроид-разработчик узнает у консультанта по исламу можно ли ему работать в нашей компании.\n",
        "Дело в том, что мы дочка Сбера, а Сбер занимается кредитованием. Согласно исламу, работать в такой отрасли — грех.\n",
        "\"\"\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIPnb4IoxKjq",
        "outputId": "c800992a-7b00-4ff2-a334-a3ffc88a8e30"
      },
      "source": [
        "correct = pd.read_csv('pos_gold - pos_gold.csv').drop(columns= ['Unnamed: 0'])\n",
        "correct['0'] = correct['0'].apply(lambda x: x.lower())\n",
        "correct = correct.to_numpy()\n",
        "correct.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_noJr48yI6e"
      },
      "source": [
        "PS. как быстро выяснилось, ни один из теггеров не воспринимает смену языка+раскладки -- лемматизатор mystem просто не создает для них разбора, pymorphy тегает как None и spacy -- 'X'=other. Поэтому было принято решение убрать разборы токенов в латинской раскладке отовсюду.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUcJAcXoR5b"
      },
      "source": [
        "## Функции, которые с помощью разных морфанализаторов (mystem, pymorphy, spacy) получают pos-теги для одного текста."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rev3Bqsi-gC"
      },
      "source": [
        "def mystem_pos(text, m = mystem.Mystem()):\n",
        "  res = [(parse['text'], parse['analysis'][0]['gr'].split(',')[0].split('=')[0]) for parse in m.analyze(text) if 'analysis' in parse.keys() and len(parse['analysis'])>0]\n",
        "  return res\n",
        "\n",
        "def pymorphy_pos(text, morph=MorphAnalyzer()):\n",
        "  res = [(w.lower(),morph.parse(w.lower())[0].tag.POS) for w in word_tokenize(text)]\n",
        "  res = [(w,pos) for w,pos in res if pos!=None]\n",
        "  return res\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "def spacy_pos(text, nlp=nlp):\n",
        "  res = [(t.text.lower(), t.pos_) for t in nlp(text) if t.text[0].isalpha() and t.pos_!='X']\n",
        "  return res"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG9JYEH60sUf",
        "outputId": "87a9f350-c448-4508-ab20-f288d6f502a1"
      },
      "source": [
        "mystem_res = np.array(sum([mystem_pos(doc) for doc in corpus], []))\n",
        "len(mystem_res)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dr2Ibyu82Qw",
        "outputId": "e4d40a8f-2765-42cb-f81f-4be4886ba97b"
      },
      "source": [
        "pymorphy_res = np.array(sum([pymorphy_pos(doc) for doc in corpus], []))\n",
        "len(pymorphy_res)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfgsuz1L2nDq",
        "outputId": "3787de31-9a64-4a5a-947a-0f388eb11e90"
      },
      "source": [
        "spacy_res = np.array(sum([spacy_pos(doc) for doc in corpus], []))\n",
        "len(spacy_res)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "207"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twu7XpBgoTW3"
      },
      "source": [
        "## Готовим все к проверке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txr1jWQ6rjJk",
        "outputId": "78ebfe55-122c-4aeb-af98-1b6fa57ae4dd"
      },
      "source": [
        "print(np.unique(correct.T[1]))\n",
        "print(np.unique(mystem_res.T[1]))\n",
        "print(np.unique(pymorphy_res.T[1]))\n",
        "print(np.unique(spacy_res.T[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'ADV' 'CONJ' 'NUM' 'PART' 'PR' 'PRO' 'S' 'V']\n",
            "['A' 'ADV' 'ADVPRO' 'APRO' 'CONJ' 'NUM' 'PART' 'PR' 'S' 'SPRO' 'V']\n",
            "['ADJF' 'ADJS' 'ADVB' 'CONJ' 'INFN' 'NOUN' 'NPRO' 'NUMR' 'PRCL' 'PRED'\n",
            " 'PREP' 'PRTF' 'PRTS' 'VERB']\n",
            "['ADJ' 'ADP' 'ADV' 'AUX' 'CCONJ' 'DET' 'NOUN' 'NUM' 'PART' 'PRON' 'PROPN'\n",
            " 'SCONJ' 'VERB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbhrnh6mrjF5"
      },
      "source": [
        "map_dict = {'A':'A',\n",
        "            'ADV':'ADV',\n",
        "            'CONJ':'CONJ',\n",
        "            'NUM':'NUM',\n",
        "            'PART':'PART',\n",
        "            'PR':'PR',\n",
        "            'PRO':'PRO',\n",
        "            'S':'S',\n",
        "            'V':'V',\n",
        "            'ADJF':'A',\n",
        "            'ADJS':'A',\n",
        "            'ADVB':'ADV',\n",
        "            'INFN':'V',\n",
        "            'NOUN':'S',\n",
        "            'NPRO':'PRO',\n",
        "            'NUMR':'NUM',\n",
        "            'PRCL':'PART',\n",
        "            'PRED':'ADV',\n",
        "            'PREP':'PR',\n",
        "            'PRTF':'V',\n",
        "            'PRTS':'V',\n",
        "            'VERB':'V',\n",
        "            'ADJ':'A',\n",
        "            'ADP':'PR',\n",
        "            'AUX':'V',\n",
        "            'CCONJ':'CONJ',\n",
        "            'DET':'PRO',\n",
        "            'PRON':'PRO',\n",
        "            'PROPN':'S',\n",
        "            'SCONJ':'CONJ',\n",
        "            'ADVPRO':'PRO',\n",
        "            'APRO':'PRO',\n",
        "            'SPRO':'PRO'}\n",
        "\n",
        "mystem_pred = np.array([(w, map_dict[pos]) for w, pos in mystem_res])\n",
        "pymorphy_pred = np.array([(w, map_dict[pos]) for w, pos in pymorphy_res])\n",
        "spacy_pred = np.array([(w, map_dict[pos]) for w, pos in spacy_res])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_mYuUY6ri8"
      },
      "source": [
        "Функуция Эккьюраси которая также учитывает не только тег, но и совпала ли токенизация с правильной"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSWpuvi8ri-Q"
      },
      "source": [
        "def accuracy(pred, correct):\n",
        "  check = [True if correct.T[0][i] in pred.T[0] else False for i in range(len(correct))]\n",
        "  return sum(check)/len(check)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NuTYtq89c4",
        "outputId": "cdd610cf-5a7e-46b8-e768-a35650f01892"
      },
      "source": [
        "print('Mystem accuracy is {}'.format(accuracy(mystem_pred, correct)))\n",
        "print('Pymorphy accuracy is {}'.format(accuracy(pymorphy_pred, correct)))\n",
        "print('Spacy accuracy is {}'.format(accuracy(spacy_pred, correct)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mystem accuracy is 0.8578431372549019\n",
            "Pymorphy accuracy is 0.9705882352941176\n",
            "Spacy accuracy is 0.9901960784313726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV2Y3uyy2xvH"
      },
      "source": [
        "## Чанкеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dznvHH9c2_Ag"
      },
      "source": [
        "(вообще это надо делать по отдельным предложениям, но я не успеваю:((( )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNMzC4gp22SZ"
      },
      "source": [
        "#прилагательное с существительным\n",
        "def chunker1(tagged_text):\n",
        "  return [' '.join((tagged_text.T[0][i],tagged_text.T[0][i+1])) for i in range(len(tagged_text)-1) if tagged_text.T[1][i]=='A' and tagged_text.T[1][i+1]=='S']\n",
        "\n",
        "#не с глагольной формой\n",
        "def chunker2(tagged_text):\n",
        "  return [' '.join((tagged_text.T[0][i],tagged_text.T[0][i+1])) for i in range(len(tagged_text)-1) if tagged_text.T[0][i]=='не' and tagged_text.T[1][i+1]=='V']\n",
        "\n",
        "#однородные члены possibly\n",
        "def chunker3(tagged_text):\n",
        "  return [' '.join((tagged_text.T[0][i-1],tagged_text.T[0][i],tagged_text.T[0][i+1])) for i in range(1,len(tagged_text)-1) if tagged_text.T[1][i-1]==tagged_text.T[1][i+1] and tagged_text.T[0][i]=='и']\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIK9WWxE4GG1",
        "outputId": "9949539d-25b5-4d09-8c51-b73bb064ad55"
      },
      "source": [
        "chunker1(spacy_pred)\n",
        "#кальяннаыя как прилагательное входит в 1% который спейси не умеет тегать"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['левой девушке',\n",
              " 'ненужный отросток',\n",
              " 'новых проекта',\n",
              " 'кальянная ресейл',\n",
              " 'транспортными средствами',\n",
              " 'водительского удостоверения']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1o0SgEq4LFl",
        "outputId": "b1f7edd9-b571-42d2-90f9-132dc5c94fa3"
      },
      "source": [
        "chunker2(spacy_pred)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['не связаны']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9cFbZpL4Lbc",
        "outputId": "a1379f00-29e8-41df-eb5f-049c4f3f1b6c"
      },
      "source": [
        "chunker3(spacy_pred)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 'смех и кринж',\n",
              " 'репом и денег']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMzj0SDM5D4z"
      },
      "source": [
        "## Последнее задание -- предложить три шаблона:\n",
        "1. 'не' + прилагательное\n",
        "2. прилагательное+существительное\n",
        "3. наречие+глагол / глагол+наречие\n",
        "4. глагол + существительное (желательно не в именительном падеже, если можем смотреть теги кроме пос)\n",
        "* Почему именно такие? В общем, чтобы находить разные значимые состовляющие (хотя я вообще за то чтобы решать эту проблему не такими шаблонами, а статистической языковой моделью -- шаблоны сделают то же самое, просто меньше шума)\n",
        "* Еще один момент, который мне тут не нравится: раз уж берем словосочетания, лучше это делать через какую-нибудь резметку зависимости, а не просто с опорой на теги"
      ]
    }
  ]
}
